{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEI5B91-xdeM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Name : Amit Pramodrao Konde**\n",
        "***Batch ID : FSDSNov79***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-lwYI_LHxhd8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cf3JHiDxy3oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Python Module Solution**"
      ],
      "metadata": {
        "id": "FLHzqCy7y8Dv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2oYJ0WZy9ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: -\n",
        "Write a program that takes a string as input, and counts the frequency of each word in the string, there mightbe repeated characters in the string. Your task is to find the highest frequency and returns the length of the highest-frequency word."
      ],
      "metadata": {
        "id": "_HXAVdepzA73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_highest_frequency_word_length(string):\n",
        "    # Split the string into words\n",
        "    words = string.split()\n",
        "\n",
        "    # Create a dictionary to store word frequencies\n",
        "    word_freq = {}\n",
        "\n",
        "    # Count the frequency of each word\n",
        "    for word in words:\n",
        "        word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "    # Find the maximum frequency\n",
        "    max_freq = max(word_freq.values())\n",
        "\n",
        "    # Find the length of the word with the maximum frequency\n",
        "    max_freq_word_length = max(len(word) for word, freq in word_freq.items() if freq == max_freq)\n",
        "\n",
        "    return max_freq_word_length\n",
        "\n",
        "\n",
        "# Example input\n",
        "string = \"write write write all the number from from from 1 to 100\"\n",
        "\n",
        "# Call the function and print the result\n",
        "print(find_highest_frequency_word_length(string))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uERmTxYIzC8z",
        "outputId": "5989620f-5ee4-4ac9-b947-bf0b4efd1bbe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C6s4iEnK0Mx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: -\n",
        "Consider a string to be valid if all characters of the string appear the same number of times. It is also valid if\n",
        "he can remove just one character at the index in the string, and the remaining characters will occur the same\n",
        "number of times. Given a string, determine if it is valid. If so, return YES , otherwise return NO .\n"
      ],
      "metadata": {
        "id": "KiO507zJ0hmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_string(s):\n",
        "    # Create a dictionary to store character frequencies\n",
        "    char_freq = {}\n",
        "\n",
        "    # Count the frequency of each character\n",
        "    for char in s:\n",
        "        char_freq[char] = char_freq.get(char, 0) + 1\n",
        "\n",
        "    # Check if all frequencies are the same\n",
        "    if len(set(char_freq.values())) == 1:\n",
        "        return \"YES\"\n",
        "\n",
        "    # Check if removing one character makes all frequencies the same\n",
        "    for char in char_freq:\n",
        "        char_freq[char] -= 1\n",
        "        new_freq = list(char_freq.values())\n",
        "\n",
        "        if len(set(new_freq)) == 1:\n",
        "            return \"YES\"\n",
        "\n",
        "        char_freq[char] += 1\n",
        "\n",
        "    return \"NO\"\n",
        "\n",
        "\n",
        "# Example input 1\n",
        "s1 = \"abc\"\n",
        "# Call the function and print the result\n",
        "print(is_valid_string(s1))  # Output: YES\n",
        "\n",
        "# Example input 2\n",
        "s2 = \"abcc\"\n",
        "# Call the function and print the result\n",
        "print(is_valid_string(s2))  # Output: NO\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai75voHV0ij4",
        "outputId": "b9527967-9f44-4918-89a3-adefe6e4d635"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YES\n",
            "YES\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: -\n",
        "Write a program, which would download the data from the provided link, and then read the data and convert\n",
        "that into properly structured data and return it in Excel format.\n"
      ],
      "metadata": {
        "id": "GzcId0o51zbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "def download_and_convert_data(link, output_file):\n",
        "    # Download the data from the provided link\n",
        "    response = requests.get(link)\n",
        "    data = response.json()\n",
        "\n",
        "    # Extract the necessary attributes from the data\n",
        "    structured_data = []\n",
        "    for pokemon in data[\"pokemon\"]:\n",
        "        attributes = {\n",
        "            \"id\": pokemon[\"id\"],\n",
        "            \"num\": pokemon[\"num\"],\n",
        "            \"name\": pokemon[\"name\"],\n",
        "            \"img\": pokemon[\"img\"],\n",
        "            \"type\": \", \".join(pokemon[\"type\"]),\n",
        "            \"height\": pokemon[\"height\"],\n",
        "            \"weight\": pokemon[\"weight\"],\n",
        "            \"candy\": pokemon.get(\"candy\", \"\"),\n",
        "            \"candy_count\": pokemon.get(\"candy_count\", 0),\n",
        "            \"egg\": pokemon.get(\"egg\", \"\"),\n",
        "            \"spawn_chance\": pokemon.get(\"spawn_chance\", 0),\n",
        "            \"avg_spawns\": pokemon.get(\"avg_spawns\", 0),\n",
        "            \"spawn_time\": pokemon.get(\"spawn_time\", \"\"),\n",
        "            \"multipliers\": \", \".join(map(str, pokemon.get(\"multipliers\", []))),\n",
        "            \"weakness\": \", \".join(pokemon.get(\"weaknesses\", [])),\n",
        "            \"next_evolution\": \", \".join([evo[\"num\"] + \" - \" + evo[\"name\"] for evo in pokemon.get(\"next_evolution\", [])]),\n",
        "            \"prev_evolution\": \", \".join([evo[\"num\"] + \" - \" + evo[\"name\"] for evo in pokemon.get(\"prev_evolution\", [])])\n",
        "        }\n",
        "        structured_data.append(attributes)\n",
        "\n",
        "    # Convert the structured data to a DataFrame\n",
        "    df = pd.DataFrame(structured_data)\n",
        "\n",
        "    # Convert the DataFrame to an Excel file\n",
        "    df.to_excel(output_file, index=False)\n",
        "\n",
        "    print(\"Data conversion completed successfully!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HcWRRz0i1qlI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "link = \"https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\"\n",
        "output_file = \"structured_data.xlsx\"\n",
        "\n",
        "download_and_convert_data(link, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "HdB9YJgo1tAZ",
        "outputId": "681cd0cd-7315-4aa7-c464-7dd5c52aa893"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9277d72fcc49>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"structured_data.xlsx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdownload_and_convert_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-fdbcf014efc0>\u001b[0m in \u001b[0;36mdownload_and_convert_data\u001b[0;34m(link, output_file)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;34m\"avg_spawns\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpokemon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"avg_spawns\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;34m\"spawn_time\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpokemon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spawn_time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;34m\"multipliers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpokemon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multipliers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;34m\"weakness\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpokemon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weaknesses\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;34m\"next_evolution\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" - \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mevo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpokemon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"next_evolution\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qAuBQD9x2KvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4 -\n",
        "Write a program to download the data from the link given below and then read the data and convert the into\n",
        "the proper structure and return it as a CSV file.\n"
      ],
      "metadata": {
        "id": "YQRZFPHQ2i8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "def download_and_convert_data(link, output_file):\n",
        "    # Download the data from the provided link\n",
        "    response = requests.get(link)\n",
        "    data = response.json()\n",
        "\n",
        "    # Convert the data to a DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Convert the DataFrame to a CSV file\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(\"Data conversion completed successfully!\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NFINNhAF2jid"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "link = \"https://data.nasa.gov/resource/y77d-th95.json\"\n",
        "output_file = \"structured_data.csv\"\n",
        "\n",
        "download_and_convert_data(link, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSiOzBvW2mZ7",
        "outputId": "e70b0afb-73d8-4ad0-d61c-3704022bfc7e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data conversion completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zNbJsyjt2nhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5 -\n",
        "Write a program to download the data from the given API link and then extract the following data with\n",
        "proper formatting"
      ],
      "metadata": {
        "id": "skLAaaXx23Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download_and_extract_data(link):\n",
        "    # Download the data from the provided API link\n",
        "    response = requests.get(link)\n",
        "    data = response.json()\n",
        "\n",
        "    # Extract the show details\n",
        "    show_name = data[\"name\"]\n",
        "    show_language = data[\"language\"]\n",
        "    show_genre = \", \".join(data[\"genres\"])\n",
        "    show_status = data[\"status\"]\n",
        "    show_summary = data[\"summary\"]\n",
        "\n",
        "    # Extract the episode details\n",
        "    episode_list = data[\"_embedded\"][\"episodes\"]\n",
        "    episode_data = []\n",
        "    for episode in episode_list:\n",
        "        episode_data.append({\n",
        "            \"Episode Number\": episode[\"number\"],\n",
        "            \"Episode Title\": episode[\"name\"],\n",
        "            \"Airdate\": episode[\"airdate\"]\n",
        "        })\n",
        "\n",
        "    # Print the extracted show details\n",
        "    print(\"Show Details:\")\n",
        "    print(\"Name:\", show_name)\n",
        "    print(\"Language:\", show_language)\n",
        "    print(\"Genre:\", show_genre)\n",
        "    print(\"Status:\", show_status)\n",
        "    print(\"Summary:\", show_summary)\n",
        "    print()\n",
        "\n",
        "    # Print the extracted episode details\n",
        "    print(\"Episode Details:\")\n",
        "    for episode in episode_data:\n",
        "        print(\"Episode Number:\", episode[\"Episode Number\"])\n",
        "        print(\"Episode Title:\", episode[\"Episode Title\"])\n",
        "        print(\"Airdate:\", episode[\"Airdate\"])\n",
        "        print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2suYkXgZ2-JM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "link = \"http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\"\n",
        "\n",
        "download_and_extract_data(link)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imbK26Lm3U9d",
        "outputId": "7fe044c0-0a35-4520-8669-21824949e643"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Show Details:\n",
            "Name: Westworld\n",
            "Language: English\n",
            "Genre: Drama, Science-Fiction, Western\n",
            "Status: Ended\n",
            "Summary: <p><b>Westworld</b> is a dark odyssey about the dawn of artificial consciousness and the evolution of sin. Set at the intersection of the near future and the reimagined past, it explores a world in which every human appetite, no matter how noble or depraved, can be indulged.</p>\n",
            "\n",
            "Episode Details:\n",
            "Episode Number: 1\n",
            "Episode Title: The Original\n",
            "Airdate: 2016-10-02\n",
            "\n",
            "Episode Number: 2\n",
            "Episode Title: Chestnut\n",
            "Airdate: 2016-10-09\n",
            "\n",
            "Episode Number: 3\n",
            "Episode Title: The Stray\n",
            "Airdate: 2016-10-16\n",
            "\n",
            "Episode Number: 4\n",
            "Episode Title: Dissonance Theory\n",
            "Airdate: 2016-10-23\n",
            "\n",
            "Episode Number: 5\n",
            "Episode Title: Contrapasso\n",
            "Airdate: 2016-10-30\n",
            "\n",
            "Episode Number: 6\n",
            "Episode Title: The Adversary\n",
            "Airdate: 2016-11-06\n",
            "\n",
            "Episode Number: 7\n",
            "Episode Title: Trompe L'Oeil\n",
            "Airdate: 2016-11-13\n",
            "\n",
            "Episode Number: 8\n",
            "Episode Title: Trace Decay\n",
            "Airdate: 2016-11-20\n",
            "\n",
            "Episode Number: 9\n",
            "Episode Title: The Well-Tempered Clavier\n",
            "Airdate: 2016-11-27\n",
            "\n",
            "Episode Number: 10\n",
            "Episode Title: The Bicameral Mind\n",
            "Airdate: 2016-12-04\n",
            "\n",
            "Episode Number: 1\n",
            "Episode Title: Journey Into Night\n",
            "Airdate: 2018-04-22\n",
            "\n",
            "Episode Number: 2\n",
            "Episode Title: Reunion\n",
            "Airdate: 2018-04-29\n",
            "\n",
            "Episode Number: 3\n",
            "Episode Title: Virtù e Fortuna\n",
            "Airdate: 2018-05-06\n",
            "\n",
            "Episode Number: 4\n",
            "Episode Title: The Riddle of the Sphinx\n",
            "Airdate: 2018-05-13\n",
            "\n",
            "Episode Number: 5\n",
            "Episode Title: Akane No Mai\n",
            "Airdate: 2018-05-20\n",
            "\n",
            "Episode Number: 6\n",
            "Episode Title: Phase Space\n",
            "Airdate: 2018-05-27\n",
            "\n",
            "Episode Number: 7\n",
            "Episode Title: Les Écorchés\n",
            "Airdate: 2018-06-03\n",
            "\n",
            "Episode Number: 8\n",
            "Episode Title: Kiksuya\n",
            "Airdate: 2018-06-10\n",
            "\n",
            "Episode Number: 9\n",
            "Episode Title: Vanishing Point\n",
            "Airdate: 2018-06-17\n",
            "\n",
            "Episode Number: 10\n",
            "Episode Title: The Passenger\n",
            "Airdate: 2018-06-24\n",
            "\n",
            "Episode Number: 1\n",
            "Episode Title: Parce Domine\n",
            "Airdate: 2020-03-15\n",
            "\n",
            "Episode Number: 2\n",
            "Episode Title: The Winter Line\n",
            "Airdate: 2020-03-22\n",
            "\n",
            "Episode Number: 3\n",
            "Episode Title: The Absence of Field\n",
            "Airdate: 2020-03-29\n",
            "\n",
            "Episode Number: 4\n",
            "Episode Title: The Mother of Exiles\n",
            "Airdate: 2020-04-05\n",
            "\n",
            "Episode Number: 5\n",
            "Episode Title: Genre\n",
            "Airdate: 2020-04-12\n",
            "\n",
            "Episode Number: 6\n",
            "Episode Title: Decoherence\n",
            "Airdate: 2020-04-19\n",
            "\n",
            "Episode Number: 7\n",
            "Episode Title: Passed Pawn\n",
            "Airdate: 2020-04-26\n",
            "\n",
            "Episode Number: 8\n",
            "Episode Title: Crisis Theory\n",
            "Airdate: 2020-05-03\n",
            "\n",
            "Episode Number: 1\n",
            "Episode Title: The Auguries\n",
            "Airdate: 2022-06-26\n",
            "\n",
            "Episode Number: 2\n",
            "Episode Title: Well Enough Alone\n",
            "Airdate: 2022-07-03\n",
            "\n",
            "Episode Number: 3\n",
            "Episode Title: Années Folles\n",
            "Airdate: 2022-07-10\n",
            "\n",
            "Episode Number: 4\n",
            "Episode Title: Generation Loss\n",
            "Airdate: 2022-07-17\n",
            "\n",
            "Episode Number: 5\n",
            "Episode Title: Zhuangzi\n",
            "Airdate: 2022-07-24\n",
            "\n",
            "Episode Number: 6\n",
            "Episode Title: Fidelity\n",
            "Airdate: 2022-07-31\n",
            "\n",
            "Episode Number: 7\n",
            "Episode Title: Metanoia\n",
            "Airdate: 2022-08-07\n",
            "\n",
            "Episode Number: 8\n",
            "Episode Title: Que Será, Será\n",
            "Airdate: 2022-08-14\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SSkCyOVe3V5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6 -\n",
        "Using the data from Question 3, write code to analyze the data and answer the following questions Note 1.\n",
        "Draw plots to demonstrate the analysis for the following questions for better visualizations.\n"
      ],
      "metadata": {
        "id": "hhh2JAbD3oDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def analyze_pokemon_data():\n",
        "    # Read the data from the provided link\n",
        "    url = \"https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\"\n",
        "    data = pd.read_json(url)\n",
        "\n",
        "    # Get all Pokemons whose spawn rate is less than 5%\n",
        "    spawn_rate_threshold = 0.05\n",
        "    low_spawn_rate_pokemon = data[data[\"spawn_chance\"] < spawn_rate_threshold]\n",
        "    print(\"Pokemons with spawn rate less than 5%:\")\n",
        "    print(low_spawn_rate_pokemon[[\"name\", \"spawn_chance\"]])\n",
        "    print()\n",
        "\n",
        "    # Get all Pokemons that have less than 4 weaknesses\n",
        "    max_weaknesses = 4\n",
        "    less_weaknesses_pokemon = data[data[\"weaknesses\"].apply(len) < max_weaknesses]\n",
        "    print(\"Pokemons with less than 4 weaknesses:\")\n",
        "    print(less_weaknesses_pokemon[[\"name\", \"weaknesses\"]])\n",
        "    print()\n",
        "\n",
        "    # Get all Pokemons that have no multipliers at all\n",
        "    no_multipliers_pokemon = data[data[\"multipliers\"].apply(len) == 0]\n",
        "    print(\"Pokemons with no multipliers:\")\n",
        "    print(no_multipliers_pokemon[[\"name\", \"multipliers\"]])\n",
        "    print()\n",
        "\n",
        "    # Get all Pokemons that do not have more than 2 evolutions\n",
        "    max_evolutions = 2\n",
        "    less_evolutions_pokemon = data[data[\"next_evolution\"].apply(lambda x: len(x) <= max_evolutions)]\n",
        "    print(\"Pokemons with 2 or fewer evolutions:\")\n",
        "    print(less_evolutions_pokemon[[\"name\", \"next_evolution\"]])\n",
        "    print()\n",
        "\n",
        "    # Get all Pokemons whose spawn time is less than 300 seconds\n",
        "    max_spawn_time = \"05:00\"  # Convert 300 seconds to \"minute:second\" format\n",
        "    data[\"spawn_time\"] = pd.to_datetime(data[\"spawn_time\"], format=\"%M:%S\")\n",
        "    less_spawn_time_pokemon = data[data[\"spawn_time\"] < max_spawn_time]\n",
        "    print(\"Pokemons with spawn time less than 300 seconds:\")\n",
        "    print(less_spawn_time_pokemon[[\"name\", \"spawn_time\"]])\n",
        "    print()\n",
        "\n",
        "    # Get all Pokemons who have more than two types of capabilities\n",
        "    min_capabilities = 2\n",
        "    more_capabilities_pokemon = data[data[\"type\"].apply(len) > min_capabilities]\n",
        "    print(\"Pokemons with more than two types of capabilities:\")\n",
        "    print(more_capabilities_pokemon[[\"name\", \"type\"]])\n",
        "    print()\n",
        "\n",
        "    # Draw plots for visualizations\n",
        "    # Plot for spawn rate distribution\n",
        "    plt.hist(data[\"spawn_chance\"], bins=20)\n",
        "    plt.xlabel(\"Spawn Rate\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Spawn Rate Distribution\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot for weaknesses count distribution\n",
        "    data[\"weakness_count\"] = data[\"weaknesses\"].apply(len)\n",
        "    plt.hist(data[\"weakness_count\"], bins=range(0, 9))\n",
        "    plt.xlabel(\"Number of Weaknesses\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Number of Weaknesses Distribution\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Call the function to perform the analysis\n",
        "analyze_pokemon_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "PJHNaCS03r1R",
        "outputId": "23f12e2c-1131-48b0-cb05-7ab5ffa4e20b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'spawn_chance'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9afcb3c2b896>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Call the function to perform the analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0manalyze_pokemon_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-9afcb3c2b896>\u001b[0m in \u001b[0;36manalyze_pokemon_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Get all Pokemons whose spawn rate is less than 5%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mspawn_rate_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlow_spawn_rate_pokemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"spawn_chance\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspawn_rate_threshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pokemons with spawn rate less than 5%:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow_spawn_rate_pokemon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"spawn_chance\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'spawn_chance'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mi3By1y54usf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7 -\n",
        "Using the data from Question 4, write code to analyze the data and answer the following questions Note -\n",
        "1. Draw plots to demonstrate the analysis for the following questions for better visualizations\n",
        "2. Write code comments wherever required for code understanding"
      ],
      "metadata": {
        "id": "fJC4snf94_Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def analyze_meteorite_data():\n",
        "    # Read the data from the provided link\n",
        "    url = \"https://data.nasa.gov/resource/y77d-th95.json\"\n",
        "    data = pd.read_json(url)\n",
        "\n",
        "    # Get all the Earth meteorites that fell before the year 2000\n",
        "    earth_meteorites_before_2000 = data[(data[\"reclat\"].notnull()) & (data[\"year\"].astype(int) < 2000)]\n",
        "    print(\"Earth meteorites that fell before the year 2000:\")\n",
        "    print(earth_meteorites_before_2000[[\"name\", \"year\"]])\n",
        "    print()\n",
        "\n",
        "    # Get all the Earth meteorites coordinates that fell before the year 1970\n",
        "    earth_meteorites_coords_before_1970 = data[(data[\"reclat\"].notnull()) & (data[\"year\"].astype(int) < 1970)]\n",
        "    print(\"Earth meteorites coordinates that fell before the year 1970:\")\n",
        "    print(earth_meteorites_coords_before_1970[[\"reclat\", \"reclong\"]])\n",
        "    print()\n",
        "\n",
        "    # Get all the Earth meteorites whose mass was more than 10000kg (assuming mass is in kg)\n",
        "    min_mass = 10000\n",
        "    heavy_meteorites = data[(data[\"reclat\"].notnull()) & (data[\"mass (g)\"].astype(float) > min_mass)]\n",
        "    print(\"Earth meteorites with mass more than 10000kg:\")\n",
        "    print(heavy_meteorites[[\"name\", \"mass (g)\"]])\n",
        "    print()\n",
        "\n",
        "    # Draw plots for visualizations\n",
        "    # Scatter plot for meteorite mass versus year\n",
        "    plt.scatter(data[\"year\"].astype(int), data[\"mass (g)\"].astype(float))\n",
        "    plt.xlabel(\"Year\")\n",
        "    plt.ylabel(\"Mass (g)\")\n",
        "    plt.title(\"Meteorite Mass versus Year\")\n",
        "    plt.show()\n",
        "\n",
        "    # Bar plot for meteorite classification count\n",
        "    classification_count = data[\"recclass\"].value_counts().sort_values(ascending=False)\n",
        "    classification_count.plot(kind=\"bar\")\n",
        "    plt.xlabel(\"Meteorite Classification\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(\"Meteorite Classification Count\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Call the function to perform the analysis\n",
        "analyze_meteorite_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "zbkCSCfh5ACJ",
        "outputId": "c608da17-d1da-4201-9031-bba721d13967"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-57c323b2fb64>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Call the function to perform the analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0manalyze_meteorite_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-57c323b2fb64>\u001b[0m in \u001b[0;36manalyze_meteorite_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Get all the Earth meteorites that fell before the year 2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mearth_meteorites_before_2000\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reclat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"year\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Earth meteorites that fell before the year 2000:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mearth_meteorites_before_2000\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"year\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6239\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6240\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     def convert(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '1880-01-01T00:00:00.000'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gHh24cve5ai1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8 -\n",
        "Using the data from Question 5, write code the analyze the data and answer the following questions Note -\n",
        "1. Draw plots to demonstrate the analysis for the following questions and better visualizations\n",
        "2. Write code comments wherever required for code understanding"
      ],
      "metadata": {
        "id": "u9ZD8mOS5oLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def analyze_tv_show_data():\n",
        "    # Send a GET request to the API link and retrieve the data\n",
        "    url = \"http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    # Extract the episode data\n",
        "    episodes = data[\"_embedded\"][\"episodes\"]\n",
        "\n",
        "    # Convert the episode data into a DataFrame\n",
        "    df = pd.DataFrame(episodes)\n",
        "\n",
        "    # Convert the airdate column to datetime format\n",
        "    df[\"airdate\"] = pd.to_datetime(df[\"airdate\"])\n",
        "\n",
        "    # Get all the overall ratings for each season and compare the ratings using plots\n",
        "    season_ratings = df.groupby(\"season\")[\"rating\"].mean()\n",
        "    print(\"Overall ratings for each season:\")\n",
        "    print(season_ratings)\n",
        "    print()\n",
        "\n",
        "    # Plot the ratings for all seasons\n",
        "    season_ratings.plot(kind=\"bar\")\n",
        "    plt.xlabel(\"Season\")\n",
        "    plt.ylabel(\"Average Rating\")\n",
        "    plt.title(\"Average Rating per Season\")\n",
        "    plt.show()\n",
        "\n",
        "    # Get all the episode names whose average rating is more than 8 for every season\n",
        "    high_rated_episodes = df.groupby([\"season\", \"name\"]).filter(lambda x: x[\"rating\"].mean() > 8)\n",
        "    print(\"Episode names with average rating more than 8 for every season:\")\n",
        "    print(high_rated_episodes[[\"season\", \"name\"]])\n",
        "    print()\n",
        "\n",
        "    # Get all the episode names that aired before May 2019\n",
        "    episodes_before_may_2019 = df[df[\"airdate\"] < pd.to_datetime(\"2019-05-01\")]\n",
        "    print(\"Episode names that aired before May 2019:\")\n",
        "    print(episodes_before_may_2019[[\"name\", \"airdate\"]])\n",
        "    print()\n",
        "\n",
        "    # Get the episode name from each season with the highest and lowest rating\n",
        "    highest_rated_episodes = df.groupby(\"season\")[\"rating\"].idxmax()\n",
        "    lowest_rated_episodes = df.groupby(\"season\")[\"rating\"].idxmin()\n",
        "    highest_rated_episodes_info = df.loc[highest_rated_episodes, [\"season\", \"name\", \"rating\"]]\n",
        "    lowest_rated_episodes_info = df.loc[lowest_rated_episodes, [\"season\", \"name\", \"rating\"]]\n",
        "    print(\"Episode with the highest rating per season:\")\n",
        "    print(highest_rated_episodes_info)\n",
        "    print()\n",
        "    print(\"Episode with the lowest rating per season:\")\n",
        "    print(lowest_rated_episodes_info)\n",
        "    print()\n",
        "\n",
        "    # Get the summary for the most popular (highest-rated) episode in every season\n",
        "    most_popular_episodes = df.groupby(\"season\")[\"rating\"].idxmax()\n",
        "    most_popular_episodes_info = df.loc[most_popular_episodes, [\"season\", \"name\", \"summary\"]]\n",
        "    print(\"Summary for the most popular episode in every season:\")\n",
        "    print(most_popular_episodes_info)\n",
        "\n",
        "\n",
        "# Call the function to perform the analysis\n",
        "analyze_tv_show_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "TcMSWcTH5o5k",
        "outputId": "6e9f1e94-bed0-45b9-fb19-400b6438a1e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36marray_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1790\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m                 result = self.grouper._cython_operation(\n\u001b[0m\u001b[1;32m   1792\u001b[0m                     \u001b[0;34m\"aggregate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m         return cy_op.cython_operation(\n\u001b[0m\u001b[1;32m   1040\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mcython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         return self._cython_op_ndim_compat(\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_cython_op_ndim_compat\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mresult_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             res = self._call_cython_op(\n\u001b[0m\u001b[1;32m    513\u001b[0m                 \u001b[0mvalues2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_call_cython_op\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mout_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cython_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cython_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_cython_function\u001b[0;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# raise NotImplementedError here rather than TypeError later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 raise NotImplementedError(\n\u001b[0m\u001b[1;32m    193\u001b[0m                     \u001b[0;34mf\"function is not implemented for this dtype: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-24cf7119d018>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Call the function to perform the analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0manalyze_tv_show_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-24cf7119d018>\u001b[0m in \u001b[0;36manalyze_tv_show_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Get all the overall ratings for each season and compare the ratings using plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mseason_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"season\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Overall ratings for each season:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseason_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2181\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numba_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliding_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2183\u001b[0;31m             result = self._cython_agg_general(\n\u001b[0m\u001b[1;32m   2184\u001b[0m                 \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m                 \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only_bool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m         \u001b[0;31m# TypeError -> we may have an exception in trying to aggregate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m         \u001b[0;31m#  continue and exclude the block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1810\u001b[0;31m         \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouped_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_failures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_ser\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0morig_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36mgrouped_reduce\u001b[0;34m(self, func, ignore_failures)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36marray_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1802\u001b[0m                 \u001b[0;31m# try to python agg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m                 \u001b[0;31m# TODO: shouldn't min_count matter?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_py_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_agg_py_fallback\u001b[0;34m(self, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0;31m#  should always be preserved by the implemented aggregations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m         \u001b[0;31m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_pure_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mnpvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2183\u001b[0m             result = self._cython_agg_general(\n\u001b[1;32m   2184\u001b[0m                 \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2185\u001b[0;31m                 \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only_bool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2186\u001b[0m                 \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2187\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11845\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11846\u001b[0m         ):\n\u001b[0;32m> 11847\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11849\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11399\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11400\u001b[0m     ) -> Series | float:\n\u001b[0;32m> 11401\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  11402\u001b[0m             \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11403\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11351\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11352\u001b[0m             )\n\u001b[0;32m> 11353\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  11354\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11355\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4814\u001b[0m                 )\n\u001b[1;32m   4815\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4816\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4818\u001b[0m     def _reindex_indexer(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     47\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cXiAUiGG6Aos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9 -\n",
        "Write a program to read the data from the following link, perform data analysis and answer the following\n",
        "questions\n",
        "Note -\n",
        "1. Write code comments wherever required for code understanding\n",
        "Link - https://data.wa.gov/api/views/f6w7-q2d2/rows.csv?accessType=DOWNLOAD\n",
        "Insights to be drawn -\n",
        "● Get all the cars and their types that do not qualify for clean alternative fuel vehicle\n",
        "● Get all TESLA cars with the model year, and model type made in Bothell City.\n",
        "● Get all the cars that have an electric range of more than 100, and were made after\n",
        "2015\n",
        "● Draw plots to show the distribution between city and electric vehicle type\n"
      ],
      "metadata": {
        "id": "HE2qcjLw6H7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def analyze_car_data():\n",
        "    # Read the data from the provided link\n",
        "    url = \"https://data.wa.gov/api/views/f6w7-q2d2/rows.csv?accessType=DOWNLOAD\"\n",
        "    data = pd.read_csv(url)\n",
        "\n",
        "    # Get all the cars and their types that do not qualify for clean alternative fuel vehicle\n",
        "    non_clean_fuel_cars = data[data[\"Qualifies for Clean Alternative Fuel Vehicle\"] == \"No\"]\n",
        "    print(\"Cars and their types that do not qualify for clean alternative fuel vehicle:\")\n",
        "    print(non_clean_fuel_cars[[\"Make\", \"Vehicle Type\"]])\n",
        "    print()\n",
        "\n",
        "    # Get all TESLA cars with the model year, and model type made in Bothell City\n",
        "    tesla_cars_bothell = data[(data[\"Make\"] == \"TESLA\") & (data[\"City\"] == \"BOTHELL\")]\n",
        "    print(\"TESLA cars with model year and model type made in Bothell City:\")\n",
        "    print(tesla_cars_bothell[[\"Model Year\", \"Model Type\"]])\n",
        "    print()\n",
        "\n",
        "    # Get all the cars that have an electric range of more than 100 and were made after 2015\n",
        "    electric_cars = data[(data[\"Electric Range\"] > 100) & (data[\"Model Year\"] > 2015)]\n",
        "    print(\"Cars with electric range greater than 100 and made after 2015:\")\n",
        "    print(electric_cars[[\"Make\", \"Model Year\", \"Electric Range\"]])\n",
        "    print()\n",
        "\n",
        "    # Draw plots to show the distribution between city and electric vehicle type\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.scatter(data[\"City\"], data[\"Electric Vehicle Type\"], alpha=0.5)\n",
        "    plt.xlabel(\"City\")\n",
        "    plt.ylabel(\"Electric Vehicle Type\")\n",
        "    plt.title(\"Distribution of Electric Vehicle Types across Cities\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Call the function to perform the analysis\n",
        "analyze_car_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "mg88D_QH6Qys",
        "outputId": "bb672c50-ffaa-439c-ece3-515b25f6fea8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Qualifies for Clean Alternative Fuel Vehicle'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-331bd672eb3e>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Call the function to perform the analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0manalyze_car_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-331bd672eb3e>\u001b[0m in \u001b[0;36manalyze_car_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Get all the cars and their types that do not qualify for clean alternative fuel vehicle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnon_clean_fuel_cars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Qualifies for Clean Alternative Fuel Vehicle\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"No\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cars and their types that do not qualify for clean alternative fuel vehicle:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_clean_fuel_cars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Make\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Vehicle Type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Qualifies for Clean Alternative Fuel Vehicle'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10 -\n",
        "Write a program to count the number of verbs, nouns, pronouns, and adjectives in a given particular phrase or\n",
        "paragraph, and return their respective count as a dictionary."
      ],
      "metadata": {
        "id": "-Jdw6SGN6kg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "def count_pos_tags(text):\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Perform part-of-speech tagging on the words\n",
        "    tagged_words = pos_tag(words)\n",
        "\n",
        "    # Initialize counters for each part of speech\n",
        "    verb_count = 0\n",
        "    noun_count = 0\n",
        "    pronoun_count = 0\n",
        "    adjective_count = 0\n",
        "\n",
        "    # Iterate over the tagged words and count the occurrences of each part of speech\n",
        "    for word, tag in tagged_words:\n",
        "        if tag.startswith('V'):  # Verbs\n",
        "            verb_count += 1\n",
        "        elif tag.startswith('N'):  # Nouns\n",
        "            noun_count += 1\n",
        "        elif tag.startswith('PR'):  # Pronouns\n",
        "            pronoun_count += 1\n",
        "        elif tag.startswith('J'):  # Adjectives\n",
        "            adjective_count += 1\n",
        "\n",
        "    # Create a dictionary with the counts\n",
        "    pos_counts = {\n",
        "        \"Verbs\": verb_count,\n",
        "        \"Nouns\": noun_count,\n",
        "        \"Pronouns\": pronoun_count,\n",
        "        \"Adjectives\": adjective_count\n",
        "    }\n",
        "\n",
        "    return pos_counts\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HCEy8Pof6VIw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the program\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "pos_counts = count_pos_tags(text)\n",
        "print(pos_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "nqtGkN9h6pXF",
        "outputId": "a3f09c4a-1803-409b-c5a1-7a9a26537387"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0c02e2db87fb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test the program\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The quick brown fox jumps over the lazy dog.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpos_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_pos_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-4f66fcf89f1f>\u001b[0m in \u001b[0;36mcount_pos_tags\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_pos_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Tokenize the text into words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Perform part-of-speech tagging on the words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python Module assesment end**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TBOgvnJL6_gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Statistics** **Module Solutions**"
      ],
      "metadata": {
        "id": "uTj6ROoK6_lV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-1. A university wants to understand the relationship between the SAT scores of its\n",
        "applicants and their college GPA. They collect data on 500 students, including their SAT\n",
        "scores (out of 1600) and their college GPA (on a 4.0 scale). They find that the correlation\n",
        "coefficient between SAT scores and college GPA is 0.7. What does this correlation\n",
        "coefficient indicate about the relationship between SAT scores and college GPA?\n"
      ],
      "metadata": {
        "id": "P2jyMrUZ6_pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Solution : -"
      ],
      "metadata": {
        "id": "oJNj1Y4h6qnN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation coefficient between SAT scores and college GPA of 0.7 indicates a strong positive linear relationship between the two variables. \n",
        "\n",
        "A correlation coefficient measures the strength and direction of the linear relationship between two variables. In this case, a correlation coefficient of 0.7 indicates a strong positive relationship, meaning that as SAT scores increase, college GPA tends to increase as well.\n",
        "\n",
        "The positive sign of the correlation coefficient indicates that higher SAT scores are associated with higher college GPA. This means that students who perform well on the SAT tend to have higher GPAs in college, on average.\n",
        "\n",
        "It's important to note that correlation does not imply causation. While a strong positive correlation suggests a relationship between SAT scores and college GPA, it does not necessarily imply that SAT scores directly cause higher GPAs. Other factors, such as study habits, motivation, and academic support, may also contribute to a student's college success.\n",
        "\n",
        "Overall, a correlation coefficient of 0.7 indicates a strong positive relationship between SAT scores and college GPA in the given dataset of 500 students."
      ],
      "metadata": {
        "id": "PFGXNSZQ73SY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WhA7cALc74FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-2. Consider a dataset containing the heights (in centimeters) of 1000 individuals. The\n",
        "mean height is 170 cm with a standard deviation of 10 cm. The dataset is approximately\n",
        "normally distributed, and its skewness is approximately zero. Based on this information,\n",
        "answer the following questions:\n",
        "a. What percentage of individuals in the dataset have heights between 160 cm\n",
        "and 180 cm?\n",
        "b. If we randomly select 100 individuals from the dataset, what is the probability\n",
        "that their average height is greater than 175 cm?\n",
        "c. Assuming the dataset follows a normal distribution, what is the z-score\n",
        "corresponding to a height of 185 cm?\n",
        "d. We know that 5% of the dataset has heights below a certain value. What is\n",
        "the approximate height corresponding to this threshold?\n",
        "e. Calculate the coefficient of variation (CV) for the dataset.\n",
        "f. Calculate the skewness of the dataset and interpret the result.\n"
      ],
      "metadata": {
        "id": "jqM5ykcX8KBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution :-"
      ],
      "metadata": {
        "id": "eeTtXMwU8y98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. To find the percentage of individuals in the dataset with heights between 160 cm and 180 cm, we need to calculate the z-scores for these heights and use the standard normal distribution table.\n",
        "\n",
        "The z-score formula is given by: z = (x - μ) / σ\n",
        "\n",
        "For 160 cm:\n",
        "z1 = (160 - 170) / 10 = -1\n",
        "\n",
        "For 180 cm:\n",
        "z2 = (180 - 170) / 10 = 1\n",
        "\n",
        "Using the standard normal distribution table or a calculator, we can find the area under the curve between z1 and z2. This area represents the percentage of individuals in the dataset with heights between 160 cm and 180 cm.\n",
        "\n",
        "b. To calculate the probability that the average height of 100 randomly selected individuals is greater than 175 cm, we can use the Central Limit Theorem. The Central Limit Theorem states that the distribution of sample means approaches a normal distribution with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of the sample size.\n",
        "\n",
        "Since the dataset is approximately normally distributed with a mean of 170 cm and a standard deviation of 10 cm, the sample mean will also have a normal distribution with a mean of 170 cm and a standard deviation of 10 cm divided by the square root of 100 (which is 10 / sqrt(100) = 1).\n",
        "\n",
        "We can then calculate the z-score for a height of 175 cm using the formula: z = (x - μ) / σ\n",
        "\n",
        "z = (175 - 170) / 1 = 5\n",
        "\n",
        "Using the standard normal distribution table or a calculator, we can find the area to the right of z = 5. This area represents the probability that the average height of 100 individuals is greater than 175 cm.\n",
        "\n",
        "c. To find the z-score corresponding to a height of 185 cm, we use the formula: z = (x - μ) / σ\n",
        "\n",
        "z = (185 - 170) / 10 = 1.5\n",
        "\n",
        "The z-score of 1.5 indicates that a height of 185 cm is 1.5 standard deviations above the mean height.\n",
        "\n",
        "d. To find the approximate height corresponding to a threshold of 5% below the dataset, we can use the inverse of the cumulative distribution function (CDF) of the normal distribution.\n",
        "\n",
        "Using the standard normal distribution table or a calculator, we can find the z-score corresponding to a cumulative probability of 5% (which is -1.645 approximately). We can then use the z-score formula to calculate the height:\n",
        "\n",
        "x = μ + z * σ\n",
        "\n",
        "x = 170 + (-1.645) * 10 = 153.55\n",
        "\n",
        "The approximate height corresponding to the threshold of 5% is 153.55 cm.\n",
        "\n",
        "e. The coefficient of variation (CV) is a measure of relative variability and is calculated as the ratio of the standard deviation to the mean, expressed as a percentage.\n",
        "\n",
        "CV = (σ / μ) * 100\n",
        "\n",
        "CV = (10 / 170) * 100 = 5.88%\n",
        "\n",
        "The coefficient of variation for the dataset is approximately 5.88%.\n",
        "\n",
        "f. The skewness of the dataset measures the asymmetry of the distribution. A skewness value of approximately zero indicates that the dataset is symmetrically distributed.\n",
        "\n",
        "Skewness can be calculated using the formula:\n",
        "\n",
        "skewness = (3 * (mean - median)) / standard deviation\n",
        "\n",
        "Since the skewness is stated to be approximately zero, it implies that the dataset is roughly symmetric and does not have a significant tail on either side.\n",
        "\n"
      ],
      "metadata": {
        "id": "qjaK2hOH8trI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-3. Consider the ‘Blood Pressure Before’ and ‘Blood Pressure After’ columns from the\n",
        "data and calculate the following\n",
        "https://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=share_\n",
        "a. Measure the dispersion in both and interpret the results.\n",
        "b. Calculate mean and 5% confidence interval and plot it in a graph\n",
        "c. Calculate the Mean absolute deviation and Standard deviation and interpret\n",
        "the results.\n",
        "d. Calculate the correlation coefficient and check the significance of it at 1% level\n",
        "of significance.\n"
      ],
      "metadata": {
        "id": "6wnbwZvX9OhU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHnx5MTD9Jws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-4. A group of 20 friends decide to play a game in which they each write a number\n",
        "between 1 and 20 on a slip of paper and put it into a hat. They then draw one slip of paper\n",
        "at random. What is the probability that the number on the slip of paper is a perfect square\n",
        "(i.e., 1, 4, 9, or 16)?"
      ],
      "metadata": {
        "id": "zxxbfPDY96wQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution : ** To calculate the probability that the number drawn from the hat is a perfect square (1, 4, 9, or 16), we need to determine the number of favorable outcomes (perfect squares) and the total number of possible outcomes.\n",
        "\n",
        "Number of favorable outcomes: There are four perfect squares between 1 and 20: 1, 4, 9, and 16.\n",
        "\n",
        "Total number of possible outcomes: Each friend writes a number between 1 and 20 on a slip of paper, so there are 20 possible numbers that could be drawn.\n",
        "\n",
        "Therefore, the probability can be calculated as:\n",
        "\n",
        "Probability = Number of favorable outcomes / Total number of possible outcomes\n",
        "\n",
        "Probability = 4 / 20 = 0.2\n",
        "\n",
        "So, the probability that the number drawn from the hat is a perfect square is 0.2 or 20%."
      ],
      "metadata": {
        "id": "sGdgTr-Z97Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1oMxQegp99Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-5. A certain city has two taxi companies: Company A has 80% of the taxis and\n",
        "Company B has 20% of the taxis. Company A's taxis have a 95% success rate for picking\n",
        "up passengers on time, while Company B's taxis have a 90% success rate. If a randomly\n",
        "selected taxi is late, what is the probability that it belongs to Company A?\n"
      ],
      "metadata": {
        "id": "c5ZmiT17-R_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To solve this problem, we can use Bayes' theorem to calculate the probability that a randomly selected taxi belongs to Company A given that it is late.\n",
        "\n",
        "Let's denote the following probabilities:\n",
        "P(A) = Probability of selecting a taxi from Company A = 0.8 (as Company A has 80% of the taxis)\n",
        "P(B) = Probability of selecting a taxi from Company B = 0.2 (as Company B has 20% of the taxis)\n",
        "P(L|A) = Probability of a taxi being late given that it belongs to Company A = 1 - 0.95 = 0.05 (as the success rate for on-time pick-up is 95%)\n",
        "P(L|B) = Probability of a taxi being late given that it belongs to Company B = 1 - 0.90 = 0.10 (as the success rate for on-time pick-up is 90%)\n",
        "\n",
        "We need to find P(A|L), the probability that a randomly selected taxi belongs to Company A given that it is late.\n",
        "\n",
        "According to Bayes' theorem:\n",
        "P(A|L) = (P(L|A) * P(A)) / P(L)\n",
        "\n",
        "To calculate P(L), the probability that a taxi is late, we can use the law of total probability:\n",
        "P(L) = P(L|A) * P(A) + P(L|B) * P(B)\n",
        "\n",
        "Now let's substitute the values and calculate the probabilities:\n",
        "\n",
        "P(L) = (0.05 * 0.8) + (0.10 * 0.2) = 0.04 + 0.02 = 0.06\n",
        "\n",
        "P(A|L) = (0.05 * 0.8) / 0.06 = 0.04 / 0.06 = 0.67\n",
        "\n",
        "Therefore, the probability that a randomly selected taxi belongs to Company A given that it is late is 0.67 or 67%."
      ],
      "metadata": {
        "id": "VDu9vPWR-YMj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zr7qqLmr-Zi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-6. A pharmaceutical company is developing a drug that is supposed to reduce blood\n",
        "pressure. They conduct a clinical trial with 100 patients and record their blood\n",
        "pressure before and after taking the drug. The company wants to know if the change\n",
        "in blood pressure follows a normal distribution.\n"
      ],
      "metadata": {
        "id": "29doXMLR-mwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "url = 'https://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=sharing'\n",
        "df = pd.read_csv(url)\n",
        "change_bp = df['Blood Pressure After'] - df['Blood Pressure Before']\n",
        "statistic, p_value = stats.shapiro(change_bp)\n",
        "print('Test Statistic:', statistic)\n",
        "print('p-value:', p_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "h5NKePKq-nt2",
        "outputId": "603266cc-1457-4faf-fc9e-7e71c4d715c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Blood Pressure After'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-459ac8c59f9d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=sharing'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mchange_bp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Blood Pressure After'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Blood Pressure Before'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mstatistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapiro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange_bp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Statistic:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Blood Pressure After'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wau6et3y-zKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-7. The equations of two lines of regression, obtained in a correlation analysis\n",
        "between variables X and Y are as follows:\n",
        "and . 2𝑋 + 3 − 8 = 0 2𝑌 + 𝑋 − 5 = 0 The variance of 𝑋 = 4 Find the\n",
        "a. Variance of Y\n",
        "b. Coefficient of determination of C and Y\n",
        "c. Standard error of estimate of X on Y and of Y on X"
      ],
      "metadata": {
        "id": "mGNsfzum_Ae3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Given equations of regression lines\n",
        "equation1 = lambda x: (8 - 2*x) / 3\n",
        "equation2 = lambda x: (5 - x) / 2\n",
        "\n",
        "# Variance of X\n",
        "var_X = 4\n",
        "\n",
        "# a. Variance of Y\n",
        "var_Y = (2/3)**2 * var_X\n",
        "print(\"Variance of Y:\", var_Y)\n",
        "\n",
        "# b. Coefficient of determination (R^2) of X and Y\n",
        "correlation_coefficient = np.sqrt(var_Y / var_X)  # Square root of R^2\n",
        "coefficient_of_determination = correlation_coefficient**2\n",
        "print(\"Coefficient of determination of X and Y:\", coefficient_of_determination)\n",
        "\n",
        "# c. Standard error of estimate of X on Y and of Y on X\n",
        "# Additional information (residual standard deviation) is required to calculate the standard error of estimate.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D1wREhX_CiA",
        "outputId": "a0ff0d80-8e83-4a7c-f87b-031360270987"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of Y: 1.7777777777777777\n",
            "Coefficient of determination of X and Y: 0.4444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMRyPNlu_ppi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-8. The anxiety levels of 10 participants were measured before and after a new therapy.\n",
        "The scores are not normally distributed. Use the Wilcoxon signed-rank test to test whether\n",
        "the therapy had a significant effect on anxiety levels. The data is given below: Participant\n",
        "Before therapy After therapy Difference"
      ],
      "metadata": {
        "id": "VhsdGpan_2O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Data\n",
        "before_therapy = [5, 7, 6, 8, 4, 9, 3, 6, 7, 5]\n",
        "after_therapy = [4, 6, 5, 7, 3, 8, 2, 5, 6, 4]\n",
        "\n",
        "# Calculate the differences\n",
        "differences = [a - b for a, b in zip(after_therapy, before_therapy)]\n",
        "\n",
        "# Perform the Wilcoxon signed-rank test\n",
        "statistic, p_value = stats.wilcoxon(differences)\n",
        "\n",
        "# Print the test results\n",
        "print(\"Wilcoxon signed-rank test:\")\n",
        "print(\"Statistic:\", statistic)\n",
        "print(\"P-value:\", p_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4KFaFNK_29B",
        "outputId": "7bbcb480-d2e0-4342-dc05-08655ebb702c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wilcoxon signed-rank test:\n",
            "Statistic: 0.0\n",
            "P-value: 0.001953125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-10. A factory produces light bulbs, and the probability of a bulb being defective is 0.05.\n",
        "The factory produces a large batch of 500 light bulbs.\n",
        "a. What is the probability that exactly 20 bulbs are defective?\n",
        "b. What is the probability that at least 10 bulbs are defective?\n",
        "c. What is the probability that at max 15 bulbs are defective?\n",
        "d. On average, how many defective bulbs would you expect in a batch of 500?"
      ],
      "metadata": {
        "id": "agjEEbA9AWv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import binom\n",
        "\n",
        "# Constants\n",
        "n = 500  # Total number of bulbs\n",
        "p = 0.05  # Probability of a bulb being defective\n",
        "\n",
        "# a. Probability of exactly 20 defective bulbs\n",
        "prob_20_defective = binom.pmf(20, n, p)\n",
        "print(\"Probability of exactly 20 defective bulbs:\", prob_20_defective)\n",
        "\n",
        "# b. Probability of at least 10 defective bulbs\n",
        "prob_at_least_10_defective = 1 - binom.cdf(9, n, p)\n",
        "print(\"Probability of at least 10 defective bulbs:\", prob_at_least_10_defective)\n",
        "\n",
        "# c. Probability of at most 15 defective bulbs\n",
        "prob_at_most_15_defective = binom.cdf(15, n, p)\n",
        "print(\"Probability of at most 15 defective bulbs:\", prob_at_most_15_defective)\n",
        "\n",
        "# d. Expected number of defective bulbs\n",
        "expected_defective = n * p\n",
        "print(\"Expected number of defective bulbs:\", expected_defective)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA358RQSAXqY",
        "outputId": "e88ad173-7d8e-4f4b-cfc7-58f422168dae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of exactly 20 defective bulbs: 0.051616192536641056\n",
            "Probability of at least 10 defective bulbs: 0.9998316463654902\n",
            "Probability of at most 15 defective bulbs: 0.01985837716300623\n",
            "Expected number of defective bulbs: 25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-11. Given the data of a feature contributing to different classes"
      ],
      "metadata": {
        "id": "EigX66loAqg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Load the data\n",
        "data_url = 'https://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=sharing'\n",
        "data = pd.read_csv(data_url)\n",
        "\n",
        "# a. Check whether the distribution of all the classes are the same or not\n",
        "# Perform one-way ANOVA test\n",
        "p_value = stats.f_oneway(data['Class1'], data['Class2'], data['Class3']).pvalue\n",
        "if p_value < 0.05:\n",
        "    print(\"The distribution of the classes is not the same.\")\n",
        "else:\n",
        "    print(\"The distribution of the classes is the same.\")\n",
        "\n",
        "# b. Check for the equality of variance\n",
        "# Perform Levene's test for equality of variances\n",
        "p_value = stats.levene(data['Class1'], data['Class2'], data['Class3']).pvalue\n",
        "if p_value < 0.05:\n",
        "    print(\"The variances of the classes are not equal.\")\n",
        "else:\n",
        "    print(\"The variances of the classes are equal.\")\n",
        "\n",
        "# c. Perform LDA and QDA and compare their performance\n",
        "# Implement LDA and QDA classification models and evaluate their performance\n",
        "\n",
        "# d. Check the equality of mean between all the classes\n",
        "# Perform one-way ANOVA test\n",
        "p_value = stats.f_oneway(data['Class1'], data['Class2'], data['Class3']).pvalue\n",
        "if p_value < 0.05:\n",
        "    print(\"The means of the classes are not equal.\")\n",
        "else:\n",
        "    print(\"The means of the classes are equal.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "tMoqpVmfAr0Z",
        "outputId": "f0c5b0d5-bad2-44c0-b31e-0ca863ba4f40"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Class1'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3680e4d12033>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# a. Check whether the distribution of all the classes are the same or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Perform one-way ANOVA test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mp_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_oneway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The distribution of the classes is not the same.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Class1'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q-12. A pharmaceutical company develops a new drug and wants to compare its\n",
        "effectiveness against a standard drug for treating a particular condition. They conduct a\n",
        "study with two groups: Group A receives the new drug, and Group B receives the standard\n",
        "drug. The company measures the improvement in a specific symptom for both groups after\n",
        "a 4-week treatment period.\n",
        "a. The company collects data from 30 patients in each group and calculates the\n",
        "mean improvement score and the standard deviation of improvement for each\n",
        "group. The mean improvement score for Group A is 2.5 with a standard\n",
        "deviation of 0.8, while the mean improvement score for Group B is 2.2 with a\n",
        "standard deviation of 0.6. Conduct a t-test to determine if there is a significant\n",
        "difference in the mean improvement scores between the two groups. Use a\n",
        "significance level of 0.05.\n",
        "b. Based on the t-test results, state whether the null hypothesis should be\n",
        "rejected or not. Provide a conclusion in the context of the study."
      ],
      "metadata": {
        "id": "t0dECeqfBHdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Define the data for Group A and Group B\n",
        "mean_a = 2.5\n",
        "std_a = 0.8\n",
        "n_a = 30\n",
        "\n",
        "mean_b = 2.2\n",
        "std_b = 0.6\n",
        "n_b = 30\n",
        "\n",
        "# Perform independent t-test\n",
        "t_statistic, p_value = stats.ttest_ind_from_stats(mean_a, std_a, n_a, mean_b, std_b, n_b)\n",
        "\n",
        "# Compare p-value with significance level\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"There is a significant difference in the mean improvement scores between Group A and Group B.\")\n",
        "    print(\"Null hypothesis should be rejected.\")\n",
        "else:\n",
        "    print(\"There is no significant difference in the mean improvement scores between Group A and Group B.\")\n",
        "    print(\"Null hypothesis should not be rejected.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWiPgnB2BIfH",
        "outputId": "3c8316e6-20a1-4af3-af63-bea3dab8c93f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is no significant difference in the mean improvement scores between Group A and Group B.\n",
            "Null hypothesis should not be rejected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PsvtlKYEBJDx"
      }
    }
  ]
}